import os
import time
import streamlit as st
import base64
from pathlib import Path
from core import ImageSearcher, PDFSearcher, Model, AudioSearcher, CoreTools

# ======================================================
# ğŸ§  STREAMLIT CONFIGURATION
# ======================================================
st.set_page_config(
    page_title="Search Content in Multimedia Digital Archives using AI",
    layout="wide"
)

# ======================================================
# ğŸ¨ CUSTOM CSS STYLING
# ======================================================
st.markdown("""
<style>
.result-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(220px, 1fr));
    gap: 20px;
    margin-top: 25px;
}
.result-card {
    position: relative;
    background-color: #1e1e1e;
    border-radius: 14px;
    overflow: hidden;
    transition: transform 0.25s ease-in-out, box-shadow 0.25s ease-in-out;
}
.result-card:hover {
    transform: translateY(-5px);
    box-shadow: 0 0 20px rgba(255,255,255,0.2);
}
.result-card img {
    width: 100%;
    height: 100%;
    object-fit: cover;
    border-radius: 14px;
}
.overlay {
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    background: linear-gradient(180deg, rgba(0,0,0,0) 0%, rgba(0,0,0,0.9) 100%);
    color: white;
    padding: 10px;
    text-align: center;
}
.score-label {
    color: #ff6b6b;
    font-weight: 700;
    font-size: 0.9rem;
}
.source-label {
    color: #bbb;
    font-size: 0.8rem;
}
</style>
""", unsafe_allow_html=True)

# ======================================================
# ğŸš€ INITIALIZATION
# ======================================================
# Path Ï„Î¿Ï… logo
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
logo_path = os.path.join(BASE_DIR, "assets", "images", "logo.png")

# ÎœÎµÏ„Î±Ï„ÏÎ¿Ï€Î® ÎµÎ¹ÎºÏŒÎ½Î±Ï‚ ÏƒÎµ base64 Î³Î¹Î± inline ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ·
if os.path.exists(logo_path):
    with open(logo_path, "rb") as f:
        logo_base64 = base64.b64encode(f.read()).decode("utf-8")
else:
    st.warning(f"âš ï¸ Logo not found at {logo_path}")

# Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· inline logo + text
st.markdown(f"""
<div style="display:flex;align-items:center;gap:25px;margin-top:-10px;margin-bottom:20px;">
    <img src="data:image/png;base64,{logo_base64}" width="100" style="border-radius:10px;"/>
    <div>
        <h1 style="margin-bottom:0;">Content Search AI</h1>
        <p style="margin-top:4px;color:#9aa0a6;font-size:1.1rem;">
            Search Content in Multimedia Digital Archives using AI
        </p>
        <p style="margin-top:-8px;color:#9aa0a6;font-size:0.9rem;">Version 1.6</p>
    </div>
</div>
""", unsafe_allow_html=True)

DATA_DIR = "./data"
model = Model()
model.download_model()
searcher = ImageSearcher(data_dir=DATA_DIR)
audio = AudioSearcher()

pdf = PDFSearcher()
pdf.download_pdf_data()

# ======================================================
# ğŸ§­ TABS SETUP
# ======================================================
tabs = st.tabs([
    "â„¹ï¸ Application Info",
    "âš™ï¸ Application Settings",
    "ğŸ’¬ Search: Text â†’ Image",
    "ğŸ–¼ï¸ Search: Image â†’ Image",
    "ğŸ“š Search: PDF â†’ PDF",
    "ğŸ’¬ Search: Text â†’ PDF",
    "ğŸ§ Search: Text â†’ Audio",
    "ğŸ¥ Search: Video Search"
])

# ======================================================
# âš™ï¸ SETTINGS TAB WITH ACCORDIONS
# ======================================================
with tabs[1]:
    st.subheader("âš™ï¸ Application Settings")
    # ------------------------------------------------------
    # DATASET & EMBEDDINGS CONFIG
    # ------------------------------------------------------
    with st.expander("âš™ï¸ Dataset & Embeddings Configuration", expanded=False):
        st.markdown("### ğŸ§ Image Processing")
        col1, col2, col3 = st.columns([1, 1, 1], gap="medium")

        with col1:
            if st.button("ğŸ“¦ Download COCO Dataset", use_container_width=True):
                searcher.download_coco_data()
                st.success("âœ… COCO dataset downloaded successfully!")

        with col2:
            if st.button("ğŸ§  Extract Image Embeddings", use_container_width=True):
                searcher.extract_image_embeddings()
                st.success("âœ… Image embeddings created successfully!")

        with col3:
            if st.button("ğŸ’¬ Extract Caption Embeddings", use_container_width=True):
                searcher.extract_text_embeddings()
                st.success("âœ… Caption embeddings created successfully!")

        # ---------------------------------------------
        # NEW ROW â€” AUDIO
        # ---------------------------------------------
        st.markdown("### ğŸ§ Audio Processing")

        a1, a2, _ = st.columns([1, 1, 1], gap="medium")

        with a1:
            if st.button("ğŸµ Build Audio Embeddings", use_container_width=True):
                with st.spinner("Building audio embeddingsâ€¦"):
                    audio.build_all_embeddings()
                st.success("âœ… Audio embeddings built!")

        with a2:
            if st.button("ğŸ“ Build Audio Transcripts", use_container_width=True):
                with st.spinner("Transcribing audioâ€¦"):
                    audio.build_all_transcripts()
                st.success("âœ… Audio transcripts created!")

    # ------------------------------------------------------
    # DISPLAY SETTINGS
    # ------------------------------------------------------
    with st.expander("ğŸ”§ Display Settings", expanded=False):
        top_k = st.slider("Select number of results per search", 3, 30, 5)

# ======================================================
# â„¹ï¸ APP INFO TAB
# ======================================================
with tabs[0]:
    st.subheader("â„¹ï¸ Application Information")

    # ===========================
    # ABOUT THE PROJECT
    # ===========================
    with st.expander("ğŸ§  About This Project", expanded=True):
        st.markdown("""
            This system is a **unified multimodal retrieval platform** capable of searching across  
            **images, text, PDFs, and audio**, using a shared semantic embedding space.

            It demonstrates practical and research-level techniques in:
            - **Image Search** (text â†’ image, image â†’ image)  
            - **PDF Document Search** (text â†’ PDF, PDF â†’ PDF)  
            - **Audio Semantic Search** (text â†’ audio using Whisper + projection)  

            A major new milestone is the completion of the **Audio-Align v2 Emotion Model (v4)**,  
            which aligns Whisper audio embeddings with the M-CLIP text/image embedding space  
            for **high-precision audio semantic retrieval**.

            ---
            ### ğŸ§© Technologies Used
            - **Python 3.11**
            - **Streamlit** â€” interactive UI  
            - **PyTorch** â€” deep learning backend  
            - **Sentence-Transformers** â€” Multilingual CLIP  
            - **OpenAI Whisper** (fine-tuned + projection)  
            - **PyMuPDF** â€” PDF parsing  
            - **FFmpeg, TQDM, PIL, NumPy** â€” preprocessing utilities  

            ---
            ### âš™ï¸ Model Architecture Summary
            - **M-CLIP (ViT-B/32)** â€” multilingual text & image embeddings  
            - **Whisper-small encoder** â€” audio feature extraction  
            - **Audio Projection Layer (512-D)** â€” trained to align audio with CLIP space  
            - **Emotion Classification Head (6 classes)** â€” trained on RAVDESS/CREMA-D  
            - **PDF encoder** â€” semantic page-level representations  

            The combination of these models enables **cross-modal semantic retrieval**  
            across previously unrelated media types.

            ---
            ### ğŸ‘¨â€ğŸ’» Developer
            **Nikolaos Psaltakis**  
            University of West Attica  
            Department of Informatics & Computer Engineering  
            Bachelor Thesis Project â€“ Â© 2025
        """)

    # ===========================
    # VERSION HISTORY
    # ===========================
    with st.expander("ğŸ“˜ Version History", expanded=False):
        st.markdown("""
            ## ğŸŸ¢ **v1.6 â€“ Audio Search Integration (November 2025)**  
            - Added **Audio Semantic Search module** using Whisper + Projection  
            - Implemented **AudioSearcher class** (embeddings, transcripts, hybrid search)  
            - Added **dual-folder audio support** (AudioWAV + other_audio)  
            - Added **Whisper transcription engine** for audio-to-text retrieval  
            - Introduced **Hybrid Search** combining audio embeddings + transcripts  
            - Enabled **fast cached embeddings** for immediate reloading  
            - Streamlined dataset preprocessing and environment cleanup  
            - Prepared for full multimodal demonstration in Streamlit UI  

            ---
            ### ğŸŸ¢ **v1.5 â€“ Stable Release (October 2025)**
            - Added **PDF-to-PDF** & **Text-to-PDF** semantic search  
            - Introduced **App Info tab** with detailed metadata  
            - Improved Streamlit UI, multilingual support & documentation  
            - Cleaned hybrid CLIP + M-CLIP pipeline  
            - Refined similarity thresholds and result ranking  

            ### ğŸŸ  **v1.4 â€“ Core Functionality Integration (September 2025)**
            - Modular UI with Streamlit tabs  
            - Stable caching of all embeddings  
            - Added embedded settings & controls  

            ### ğŸŸ¡ **v1.3 â€“ Multilingual CLIP Integration (August 2025)**
            - M-CLIP integration with Greek + English support  
            - Added cross-modal retrieval foundation  
            - Initial PDF search engine implementation  

            ### ğŸ”µ **v1.2 â€“ Visual Search Prototype (June 2025)**
            - Text-to-image & image-to-image CLIP search  
            - COCO dataset evaluation  
            - Initial embedding store format  

            ### âšª **v1.1 â€“ Research Setup (May 2025)**
            - Environment setup, dataset initialization  
            - First preprocessing & validation tools  

            ### âš« **v1.0 â€“ Project Initialization (April 2025)**
            - Thesis planning & architecture specification  
        """)

    with st.expander("ğŸ§¾ Next Planned Updates", expanded=False):
        st.markdown("""
            - ğŸ¥ Integrate **video search** using frame-level M-CLIP embeddings  
            - ğŸšï¸ Add **hybrid audio-video retrieval**  
            - ğŸ—‚ï¸ Introduce metadata-based ranking (speaker, emotion, duration)  
            - ğŸ“Š Analytics panel for embedding similarity visualization  
        """)

# ======================================================
# ğŸ’¬ TEXT â†’ IMAGE SEARCH
# ======================================================
with tabs[2]:
    st.subheader("ğŸ’¬ Text-to-Image Search")
    query = st.text_input("âœï¸ Enter your search query")

    if st.button("ğŸ” Run Text Search"):
        if not query.strip():
            st.warning("âš ï¸ Please enter a search phrase.")
        else:
            st.info(f"Searching for: '{query}' ...")
            start = time.time()
            results = searcher.search(query, top_k=top_k, verbose=False)
            elapsed = time.time() - start

            if results:
                cols = st.columns(top_k)
                for idx, r in enumerate(results[:top_k]):
                    img_path = r["path"]
                    score = r["score"]
                    source = "COCO" if "val2017" in img_path else "Other"

                    cols[idx].image(
                        img_path,
                        caption=f"Similarity: {score * 100:.2f}% | Dataset: {source}",
                        use_container_width=True
                    )

# ======================================================
# ğŸ–¼ï¸ IMAGE â†’ IMAGE SEARCH
# ======================================================
with tabs[3]:
    st.subheader("ğŸ–¼ï¸ Image-to-Image Search")
    uploaded_file = st.file_uploader("ğŸ“¤ Upload an image", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        query_image_path = os.path.join("data/query_images", uploaded_file.name)
        os.makedirs(os.path.dirname(query_image_path), exist_ok=True)

        with open(query_image_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        st.image(query_image_path, caption="ğŸ“¸ Uploaded Image", width=250)

        if st.button("ğŸ” Run Image Search"):
            st.info("Analyzing and comparing image...")
            start = time.time()
            results = searcher.search_by_image(query_image_path, top_k=top_k)
            elapsed = time.time() - start

            if not results:
                st.warning("No similar images found.")
            else:
                st.success(f"âœ… Found {len(results)} similar images in {elapsed:.2f}s")
                cols = st.columns(top_k)
                for idx, r in enumerate(results[:top_k]):
                    img_path = r["path"]
                    score = r["score"]
                    source = "COCO" if "val2017" in img_path else "Other"

                    cols[idx].image(
                        img_path,
                        caption=f"Similarity: {score * 100:.2f}% | Dataset: {source}",
                        use_container_width=True
                    )

# ======================================================
# ğŸ“š PDF â†’ PDF SEARCH
# ======================================================
with tabs[4]:
    st.subheader("ğŸ“š PDF-to-PDF Similarity Search")

    uploaded_pdf = st.file_uploader("ğŸ“¤ Upload a PDF to compare", type=["pdf"])
    base_folder = "./data/pdfs"
    query_folder = "./data/query"
    os.makedirs(base_folder, exist_ok=True)
    os.makedirs(query_folder, exist_ok=True)

    if uploaded_pdf is not None:
        query_path = os.path.join(query_folder, uploaded_pdf.name)
        with open(query_path, "wb") as f:
            f.write(uploaded_pdf.getbuffer())

        st.success(f"âœ… Uploaded: {uploaded_pdf.name}")
        st.info("Analyzing document similarity...")

        searcher = PDFSearcher("./models/mclip_finetuned_coco_ready")

        with st.spinner("Processing and comparing PDFs..."):
            results = searcher.search_similar_pdfs(query_pdf=query_path, folder=base_folder, top_k=top_k)

        if not results:
            st.warning("âŒ No strong matches found.")
        else:
            st.success(f"âœ… Found {len(results)} similar documents.")
            for r in results:
                color = "ğŸŸ¢" if r["score"] >= 0.98 else "ğŸŸ " if r["score"] >= 0.95 else "ğŸ”´"
                st.markdown(f"### {color} {r['file']} â€” Page {r['page']} â€” Score: `{r['score']:.4f}`")
                st.caption(f"**Snippet:** {r['snippet']}")
                pdf_path = os.path.join(base_folder, r["file"])
                with open(pdf_path, "rb") as f:
                    pdf_data = f.read()
                st.download_button(
                    label=f"â¬‡ï¸ Download {r['file']}",
                    data=pdf_data,
                    file_name=r["file"],
                    mime="application/pdf"
                )
                st.markdown("---")

# ======================================================
# ğŸ’¬ TEXT â†’ PDF SEARCH
# ======================================================
with tabs[5]:
    st.subheader("ğŸ’¬ Text-to-PDF Semantic Search")
    query_text = st.text_area("âœï¸ Enter your search text:", placeholder="e.g. deep learning in medical imaging")

    base_folder = "./data/pdfs"
    os.makedirs(base_folder, exist_ok=True)

    if st.button("ğŸ” Run Text â†’ PDF Search"):
        if not query_text.strip():
            st.warning("âš ï¸ Please enter text before searching.")
        else:
            st.info(f"Searching for: '{query_text}' ...")

            searcher = PDFSearcher("./models/mclip_finetuned_coco_ready")

            with st.spinner("Analyzing PDFs..."):
                results = searcher.search_by_text(query_text, folder=base_folder, top_k=top_k)

            if not results:
                st.warning("No matching PDFs found.")
            else:
                st.success(f"âœ… Found {len(results)} relevant PDFs!")
                for r in results:
                    st.markdown(f"### ğŸ“„ {r['file']} (Page {r['page']}) â€” Score: `{r['score']:.4f}`")
                    st.caption(f"**Snippet:** {r['snippet']}")
                    pdf_path = os.path.join(base_folder, r["file"])
                    with open(pdf_path, "rb") as f:
                        pdf_data = f.read()
                    st.download_button(
                        label=f"â¬‡ï¸ Download {r['file']}",
                        data=pdf_data,
                        file_name=r["file"],
                        mime="application/pdf",
                        key=f"download_{r['file']}_{r['page']}"
                    )

# ======================================================
# ğŸ§ AUDIO SEARCH (PLACEHOLDER)
# ======================================================
with tabs[6]:
    st.subheader("ğŸ§ Text-to-Audio Search (Semantic + Emotion + Language Filter)")

    query = st.text_input("ğŸ” Enter your audio search phrase")

    if st.button("Run Audio Search", use_container_width=True):
        if not query.strip():
            st.warning("âš ï¸ Please enter a phrase.")
        else:
            with st.spinner("Searching audioâ€¦"):
                results = audio.search_semantic_emotion(query, top_k=top_k)

            if not results:
                st.error("âŒ No matching audio found.")
            else:
                st.success(f"âœ… Found {len(results)} audio matches!")

                for r in results:
                    fname = r["filename"]
                    folder = r["folder"]
                    semantic = r["similarity"]
                    emotion = r.get("emotion", None)
                    transcript = r.get("transcript", "")
                    lang = r.get("text_language", "unknown")

                    #f"[{i}] {r['filename']}  ({r['folder']})"
                    # Convert Windows path â†’ POSIX
                    full_path = Path(r["full_path"]).as_posix()

                    tools = CoreTools(full_path)

                    st.markdown(f"""
                    ### ğŸµ {fname}
                    **Folder:** `{folder}`  
                    ğŸŒ **Language:** `{lang}`  
                    ğŸ”Š **Semantic Similarity:** `{semantic:.3f}`  
                    ğŸ­ **Emotion:** `{emotion}`
                    """)
                    tools.plot_waveform_and_spectrogram()

                    with st.expander("ğŸ“„ Transcript"):
                        st.write(transcript)

                    # === AUDIO PLAYER ===
                    try:
                        with open(full_path, "rb") as f:
                            st.audio(f.read(), format="audio/wav")
                        st.caption(full_path)
                    except Exception as e:
                        st.error(f"Could not load audio file `{full_path}`: {e}")

                    st.markdown("---")

# ======================================================
# ğŸ¥ VIDEO SEARCH (PLACEHOLDER)
# ======================================================
with tabs[7]:
    st.subheader("ğŸ¥ Video Search (Coming Soon)")
    st.info("Video similarity search will be implemented in a future version.")
